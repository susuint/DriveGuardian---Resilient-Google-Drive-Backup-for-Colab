# -*- coding: utf-8 -*-
"""
================================================================================
    GOOGLE DRIVE BACKUP TOOL v1.9.1 - MANUAL RESUME OPTIMIZED
    Tá»‘i Æ°u cho Manual Resume - Dá»«ng runtime vÃ  cháº¡y láº¡i ngÃ y hÃ´m sau
================================================================================

PHIÃŠN Báº¢N: 1.9.1 FINAL
NGÃ€Y: February 02, 2026

WORKFLOW KHUYáº¾N NGHá»Š:
1. Cháº¡y backup bÃ¬nh thÆ°á»ng
2. Náº¿u gáº·p rate limit â†’ Dá»ªNG RUNTIME NGAY (Runtime â†’ Disconnect and delete runtime)
3. Äá»£i 24h
4. Khá»Ÿi Ä‘á»™ng láº¡i notebook â†’ ChÆ°Æ¡ng trÃ¬nh Tá»° Äá»˜NG RESUME

TÃNH NÄ‚NG Má»šI v1.9.1:
âœ… Auto-detect resume mode (khÃ´ng cáº§n chá»n manual)
âœ… ThÃ´ng bÃ¡o rÃµ rÃ ng khi nÃªn dá»«ng runtime
âœ… Checkpoint sau má»—i file thÃ nh cÃ´ng
âœ… Smart resume - tá»± Ä‘á»™ng phÃ¡t hiá»‡n tráº¡ng thÃ¡i
âœ… Khuyáº¿n nghá»‹ Dá»ªNG RUNTIME thay vÃ¬ chá»

================================================================================
"""

# ============================================================
# BÆ¯á»šC 1: CÃ€I Äáº¶T THÆ¯ VIá»†N
# ============================================================

print("ğŸ“¦ Äang cÃ i Ä‘áº·t thÆ° viá»‡n...")
import subprocess
import sys

packages = [
    'google-auth',
    'google-auth-oauthlib', 
    'google-auth-httplib2',
    'google-api-python-client',
    'tqdm',
    'requests',
    'psutil'
]

for package in packages:
    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', package])

print("âœ… HoÃ n táº¥t cÃ i Ä‘áº·t thÆ° viá»‡n!\n")


# ============================================================
# BÆ¯á»šC 2: IMPORT THÆ¯ VIá»†N
# ============================================================

import os
import json
import hashlib
import time
from datetime import datetime, timedelta
from pathlib import Path
import io
import logging
import gc
from threading import Lock
import concurrent.futures
import multiprocessing

# Google Drive API
from google.colab import auth
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload, MediaIoBaseDownload
from googleapiclient.errors import HttpError
from google.auth import default

# Progress bar
from tqdm.notebook import tqdm

# System monitoring
import psutil

# Táº¯t warnings
logging.getLogger('google_auth_httplib2').setLevel(logging.ERROR)


# ============================================================
# âš™ï¸  BÆ¯á»šC 3: Cáº¤U HÃŒNH CHÃNH - CHá»ˆNH Sá»¬A á» ÄÃ‚Y
# ============================================================

# ğŸ“ FOLDER IDs (Báº®T BUá»˜C - THAY THáº¾ ID Cá»¦A Báº N VÃ€O ÄÃ‚Y)
# Láº¥y ID tá»« URL folder: drive.google.com/drive/folders/XXX...
SOURCE_FOLDER_ID = 'YOUR_SOURCE_FOLDER_ID_HERE'    # <--- Thay ID folder nguá»“n cáº§n backup vÃ o Ä‘Ã¢y
BACKUP_PARENT_ID = 'YOUR_DESTINATION_FOLDER_ID_HERE' # <--- Thay ID folder Ä‘Ã­ch (nÆ¡i chá»©a backup) vÃ o Ä‘Ã¢y

# ğŸ·ï¸  Folder suffix
FOLDER_SUFFIX = '_BACKUP'

# ğŸš€ Workers
MAX_WORKERS = None  # Auto-detect

# ğŸ›¡ï¸  Rate Limit Protection
MAX_CONSECUTIVE_RATE_LIMIT_ERRORS = 3   # Dá»«ng sau 3 lá»—i
RATE_LIMIT_COOLDOWN_HOURS = 24          # Cooldown 24h

# ğŸ“ Files
LOG_FILE = 'backup_log.json'
STATE_FILE = 'backup_state.json'

# ğŸ¯ MANUAL RESUME MODE (Máº·c Ä‘á»‹nh)
# True = Äá» xuáº¥t Dá»ªNG RUNTIME khi gáº·p rate limit
# False = Tá»± Ä‘á»™ng retry (khÃ´ng khuyáº¿n nghá»‹)
MANUAL_RESUME_MODE = True

print("="*80)
print("âš™ï¸  Cáº¤U HÃŒNH:")
print("="*80)
print(f"ğŸ“ Source: {SOURCE_FOLDER_ID}")
print(f"ğŸ“ Backup Parent: {BACKUP_PARENT_ID}")
print(f"ğŸ¯ Resume Mode: {'MANUAL (Khuyáº¿n nghá»‹)' if MANUAL_RESUME_MODE else 'AUTO'}")
print("="*80 + "\n")


# ============================================================
# BÆ¯á»šC 4: XÃC THá»°C GOOGLE DRIVE
# ============================================================

print("ğŸ” Äang xÃ¡c thá»±c vá»›i Google Drive...")
auth.authenticate_user()
creds, _ = default()
drive_service = build('drive', 'v3', credentials=creds)
print("âœ… XÃ¡c thá»±c thÃ nh cÃ´ng!\n")


# ============================================================
# BÆ¯á»šC 5: Äá»ŠNH NGHÄ¨A CLASS
# ============================================================

class BackupState:
    """Quáº£n lÃ½ tráº¡ng thÃ¡i backup vá»›i manual resume tá»‘i Æ°u"""
    
    def __init__(self, state_file='backup_state.json'):
        self.state_file = state_file
        self.state = self.load_state()
    
    def load_state(self):
        """Load tráº¡ng thÃ¡i tá»« file"""
        if os.path.exists(self.state_file):
            try:
                with open(self.state_file, 'r', encoding='utf-8') as f:
                    state = json.load(f)
                    print(f"ğŸ“‚ ÄÃ£ load state tá»« {self.state_file}")
                    return state
            except:
                print(f"âš ï¸  KhÃ´ng thá»ƒ load state, táº¡o má»›i...")
        
        return {
            'status': 'new',
            'current_folder': None,
            'pending_files': [],
            'failed_files': [],
            'consecutive_rate_limit_errors': 0,
            'last_rate_limit_time': None,
            'backup_folder_id': None,
            'total_files_processed': 0,
            'created_at': datetime.now().isoformat(),
            'updated_at': datetime.now().isoformat()
        }
    
    def save_state(self):
        """LÆ°u tráº¡ng thÃ¡i - Checkpoint sau má»—i thay Ä‘á»•i"""
        self.state['updated_at'] = datetime.now().isoformat()
        with open(self.state_file, 'w', encoding='utf-8') as f:
            json.dump(self.state, f, indent=2, ensure_ascii=False)
    
    def update(self, **kwargs):
        """Update vÃ  lÆ°u ngay"""
        self.state.update(kwargs)
        self.save_state()
    
    def can_resume(self):
        """Kiá»ƒm tra cÃ³ thá»ƒ resume khÃ´ng"""
        if self.state['last_rate_limit_time']:
            try:
                last_error = datetime.fromisoformat(self.state['last_rate_limit_time'])
                now = datetime.now()
                hours_passed = (now - last_error).total_seconds() / 3600
                
                if hours_passed < RATE_LIMIT_COOLDOWN_HOURS:
                    remaining = RATE_LIMIT_COOLDOWN_HOURS - hours_passed
                    next_time = last_error + timedelta(hours=RATE_LIMIT_COOLDOWN_HOURS)
                    
                    print(f"\nâ° Cáº¦N Äá»¢I THÃŠM {remaining:.1f} GIá»œ")
                    print(f"ğŸ• Thá»­ láº¡i sau: {next_time.strftime('%Y-%m-%d %H:%M:%S')}")
                    print(f"ğŸ’¡ Khuyáº¿n nghá»‹: Äá»£i Ä‘á»§ thá»i gian rá»“i khá»Ÿi Ä‘á»™ng láº¡i notebook\n")
                    return False
            except:
                pass
        
        return True
    
    def reset_rate_limit_counter(self):
        """Reset counter"""
        self.state['consecutive_rate_limit_errors'] = 0
        self.save_state()
    
    def increment_rate_limit_error(self):
        """TÄƒng counter"""
        self.state['consecutive_rate_limit_errors'] += 1
        self.state['last_rate_limit_time'] = datetime.now().isoformat()
        self.save_state()
        return self.state['consecutive_rate_limit_errors']
    
    def should_auto_resume(self):
        """Kiá»ƒm tra xem cÃ³ nÃªn tá»± Ä‘á»™ng resume khÃ´ng"""
        # Náº¿u status = paused vÃ  Ä‘Ã£ qua 24h
        if self.state['status'] == 'paused':
            if self.can_resume():
                return True
        return False


class DriveBackupManager:
    """Backup Manager tá»‘i Æ°u cho manual resume"""
    
    def __init__(self, service, log_file='backup_log.json', state_file='backup_state.json', 
                 max_workers=None, manual_mode=True):
        self.service = service
        self.log_file = log_file
        self.backup_log = self.load_log()
        self.backup_state = BackupState(state_file)
        self.local_temp_dir = '/content/temp_backup'
        os.makedirs(self.local_temp_dir, exist_ok=True)
        self.manual_mode = manual_mode
        
        if max_workers is None:
            self.max_workers = self._auto_detect_workers()
        else:
            self.max_workers = max_workers
        
        self.log_lock = Lock()
        self.state_lock = Lock()
        self.download_stats = {'success': 0, 'failed': 0, 'skipped': 0}
        self.upload_stats = {'success': 0, 'failed': 0}
        self.creds, _ = default()
        self.should_stop = False
        
        print(f"ğŸš€ Workers: {self.max_workers}")
        print(f"ğŸ¯ Mode: {'MANUAL RESUME (Khuyáº¿n nghá»‹)' if manual_mode else 'AUTO RESUME'}\n")
    
    def __del__(self):
        """Cleanup"""
        try:
            if hasattr(self, 'local_temp_dir') and os.path.exists(self.local_temp_dir):
                for file in os.listdir(self.local_temp_dir):
                    try:
                        os.remove(os.path.join(self.local_temp_dir, file))
                    except:
                        pass
            gc.collect()
        except:
            pass
    
    def _auto_detect_workers(self):
        """Auto detect workers"""
        try:
            memory = psutil.virtual_memory()
            available_gb = memory.available / (1024 ** 3)
            cpu_count = multiprocessing.cpu_count()
            
            workers_by_ram = int(available_gb / 0.3)
            workers_by_cpu = cpu_count
            optimal_workers = max(3, min(workers_by_ram, workers_by_cpu, 8))
            
            print(f"ğŸ’¾ RAM: {available_gb:.1f}GB | ğŸ–¥ï¸  CPU: {cpu_count}")
            return optimal_workers
        except:
            return 4
    
    def _get_thread_local_service(self):
        """Thread-local service"""
        return build('drive', 'v3', credentials=self.creds)
    
    def load_log(self):
        """Load log"""
        if os.path.exists(self.log_file):
            try:
                with open(self.log_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except:
                pass
        return {'backed_up_files': {}, 'last_run': None}
    
    def save_log(self):
        """Save log"""
        with self.log_lock:
            self.backup_log['last_run'] = datetime.now().isoformat()
            with open(self.log_file, 'w', encoding='utf-8') as f:
                json.dump(self.backup_log, f, indent=2, ensure_ascii=False)
    
    def is_rate_limit_error(self, error):
        """Kiá»ƒm tra rate limit"""
        if isinstance(error, HttpError):
            return error.resp.status == 403 and 'userRateLimitExceeded' in str(error)
        return False
    
    def _handle_rate_limit_exceeded(self):
        """Xá»­ lÃ½ rate limit - Khuyáº¿n nghá»‹ MANUAL"""
        print("\n" + "="*80)
        print("ğŸš« VÆ¯á»¢T QUÃ GIá»šI Háº N RATE LIMIT!")
        print("="*80)
        print(f"âŒ ÄÃ£ gáº·p {MAX_CONSECUTIVE_RATE_LIMIT_ERRORS} lá»—i rate limit liÃªn tiáº¿p")
        print(f"ğŸ’¾ ÄÃ£ lÆ°u tráº¡ng thÃ¡i vÃ o: {self.backup_state.state_file}")
        
        if self.manual_mode:
            print("\n" + "ğŸ¯ KHUYáº¾N NGHá»Š - MANUAL RESUME:")
            print("="*80)
            print("1ï¸âƒ£  Dá»ªNG RUNTIME NGAY:")
            print("   â†’ Click: Runtime â†’ Disconnect and delete runtime")
            print("   â†’ Hoáº·c: Runtime â†’ Manage sessions â†’ Terminate")
            print("\n2ï¸âƒ£  Äá»¢I 24 GIá»œ")
            
            next_run = datetime.now() + timedelta(hours=RATE_LIMIT_COOLDOWN_HOURS)
            print(f"\n3ï¸âƒ£  KHá»I Äá»˜NG Láº I SAU: {next_run.strftime('%Y-%m-%d %H:%M:%S')}")
            print("   â†’ Má»Ÿ láº¡i notebook nÃ y")
            print("   â†’ Cháº¡y toÃ n bá»™ â†’ Tá»± Ä‘á»™ng resume")
            
            print("\nğŸ“Š TRáº NG THÃI ÄÃƒ LÆ¯U:")
            print(f"   âœ… Files Ä‘Ã£ backup: {len(self.backup_log['backed_up_files'])}")
            print(f"   â³ Files Ä‘ang chá»: {len(self.backup_state.state['pending_files'])}")
            print(f"   âŒ Files tháº¥t báº¡i: {len(self.backup_state.state['failed_files'])}")
            print("="*80)
            
            print("\nâš ï¸  LÆ¯U Ã: KhÃ´ng cáº§n lÃ m gÃ¬ thÃªm, chá»‰ cáº§n dá»«ng runtime!")
            print("ğŸ’¡ State Ä‘Ã£ Ä‘Æ°á»£c lÆ°u an toÃ n, báº¡n cÃ³ thá»ƒ táº¯t mÃ¡y/Ä‘Ã³ng tab")
        else:
            print(f"\nâ° Äá»£i {RATE_LIMIT_COOLDOWN_HOURS}h rá»“i cháº¡y láº¡i")
        
        print("="*80 + "\n")
        
        self.should_stop = True
        self.backup_state.update(status='paused')
    
    def get_file_info(self, file_id):
        """Get file info"""
        try:
            return self.service.files().get(
                fileId=file_id,
                fields='id, name, size, md5Checksum, mimeType'
            ).execute()
        except HttpError as e:
            print(f"âŒ Lá»—i: {e}")
            return None
    
    def download_file(self, file_id, file_name, file_size=None, max_retries=3, service=None):
        """Download file"""
        if self.should_stop:
            return None
        
        if service is None:
            service = self.service
        
        local_path = os.path.join(self.local_temp_dir, file_name)
        
        for attempt in range(max_retries):
            fh = None
            pbar = None
            
            try:
                request = service.files().get_media(fileId=file_id)
                fh = io.FileIO(local_path, 'wb')
                downloader = MediaIoBaseDownload(fh, request, chunksize=10*1024*1024)
                
                done = False
                pbar = tqdm(total=100, desc=f"ğŸ“¥ {file_name[:30]}", unit='%', leave=False)
                
                while not done:
                    status, done = downloader.next_chunk()
                    if status:
                        pbar.update(int(status.progress() * 100) - pbar.n)
                
                pbar.close()
                pbar = None
                fh.close()
                fh = None
                
                if file_size:
                    local_size = os.path.getsize(local_path)
                    if local_size != int(file_size):
                        raise Exception(f"Size mismatch")
                
                print(f"âœ… Downloaded: {file_name}")
                return local_path
            
            except Exception as e:
                if self.is_rate_limit_error(e):
                    print(f"ğŸš« Rate limit: {file_name}")
                    with self.state_lock:
                        count = self.backup_state.increment_rate_limit_error()
                        if count >= MAX_CONSECUTIVE_RATE_LIMIT_ERRORS:
                            self._handle_rate_limit_exceeded()
                            return None
                
                print(f"âš ï¸  Download attempt {attempt + 1}/{max_retries} failed")
                
                if os.path.exists(local_path):
                    try:
                        os.remove(local_path)
                    except:
                        pass
                
                if attempt < max_retries - 1:
                    time.sleep(2 ** attempt)
                else:
                    print(f"âŒ Failed: {file_name}")
                    return None
            
            finally:
                if pbar:
                    try:
                        pbar.close()
                    except:
                        pass
                if fh:
                    try:
                        fh.close()
                    except:
                        pass
        
        return None
    
    def upload_file(self, local_path, file_name, parent_folder_id, original_md5=None, max_retries=3, service=None):
        """Upload file"""
        if self.should_stop:
            return None
        
        if service is None:
            service = self.service
        
        for attempt in range(max_retries):
            uploaded_file_id = None
            
            try:
                file_metadata = {
                    'name': file_name,
                    'parents': [parent_folder_id]
                }
                
                media = MediaFileUpload(local_path, resumable=True, chunksize=5*1024*1024)
                file = service.files().create(
                    body=file_metadata,
                    media_body=media,
                    fields='id, name, size, md5Checksum'
                ).execute()
                
                uploaded_file_id = file['id']
                
                if original_md5 and file.get('md5Checksum') != original_md5:
                    try:
                        service.files().delete(fileId=uploaded_file_id).execute()
                    except:
                        pass
                    raise Exception("MD5 mismatch")
                
                print(f"âœ… Uploaded: {file_name}")
                
                # Reset counter khi thÃ nh cÃ´ng
                with self.state_lock:
                    self.backup_state.reset_rate_limit_counter()
                
                return uploaded_file_id
            
            except Exception as e:
                if self.is_rate_limit_error(e):
                    print(f"ğŸš« RATE LIMIT: {file_name}")
                    
                    with self.state_lock:
                        count = self.backup_state.increment_rate_limit_error()
                        print(f"âš ï¸  Lá»—i thá»© {count}/{MAX_CONSECUTIVE_RATE_LIMIT_ERRORS}")
                        
                        if count >= MAX_CONSECUTIVE_RATE_LIMIT_ERRORS:
                            self._handle_rate_limit_exceeded()
                            return None
                    
                    if uploaded_file_id:
                        try:
                            service.files().delete(fileId=uploaded_file_id).execute()
                        except:
                            pass
                    
                    wait_time = min(60 * (2 ** attempt), 300)
                    print(f"â³ Chá» {wait_time}s...")
                    time.sleep(wait_time)
                    continue
                
                print(f"âš ï¸  Upload attempt {attempt + 1}/{max_retries} failed")
                
                if uploaded_file_id:
                    try:
                        service.files().delete(fileId=uploaded_file_id).execute()
                    except:
                        pass
                
                if attempt < max_retries - 1:
                    time.sleep(2 ** attempt)
                else:
                    print(f"âŒ Failed: {file_name}")
                    return None
        
        return None
    
    def create_folder(self, folder_name, parent_id=None):
        """Táº¡o folder"""
        try:
            file_metadata = {
                'name': folder_name,
                'mimeType': 'application/vnd.google-apps.folder'
            }
            if parent_id:
                file_metadata['parents'] = [parent_id]
            
            folder = self.service.files().create(
                body=file_metadata,
                fields='id, name'
            ).execute()
            
            print(f"ğŸ“ Created: {folder_name}")
            return folder['id']
        except HttpError as e:
            print(f"âŒ Error: {e}")
            return None
    
    def list_files_in_folder(self, folder_id):
        """List files"""
        items = []
        page_token = None
        
        try:
            while True:
                response = self.service.files().list(
                    q=f"'{folder_id}' in parents and trashed=false",
                    fields='nextPageToken, files(id, name, mimeType, size, md5Checksum)',
                    pageToken=page_token,
                    pageSize=100
                ).execute()
                
                items.extend(response.get('files', []))
                page_token = response.get('nextPageToken')
                
                if not page_token:
                    break
            
            return items
        except HttpError as e:
            print(f"âŒ Error: {e}")
            return []
    
    def process_single_file(self, item, backup_folder_id):
        """Xá»­ lÃ½ 1 file - LÆ°u state sau má»—i file"""
        if self.should_stop:
            with self.state_lock:
                if item not in self.backup_state.state['pending_files']:
                    self.backup_state.state['pending_files'].append(item)
                    self.backup_state.save_state()
            return False
        
        item_id = item['id']
        item_name = item['name']
        file_size = item.get('size')
        original_md5 = item.get('md5Checksum')
        
        thread_service = None
        local_path = None
        
        try:
            thread_service = self._get_thread_local_service()
            
            # Check Ä‘Ã£ backup chÆ°a
            with self.log_lock:
                if item_id in self.backup_log['backed_up_files']:
                    print(f"â­ï¸  Skipped: {item_name}")
                    self.download_stats['skipped'] += 1
                    return True
            
            # Download
            local_path = self.download_file(item_id, item_name, file_size, service=thread_service)
            
            if self.should_stop:
                with self.state_lock:
                    if item not in self.backup_state.state['pending_files']:
                        self.backup_state.state['pending_files'].append(item)
                        self.backup_state.save_state()
                return False
            
            if local_path and os.path.exists(local_path):
                self.download_stats['success'] += 1
                
                # Upload
                uploaded_id = self.upload_file(
                    local_path,
                    item_name,
                    backup_folder_id,
                    original_md5,
                    service=thread_service
                )
                
                if self.should_stop:
                    with self.state_lock:
                        if item not in self.backup_state.state['pending_files']:
                            self.backup_state.state['pending_files'].append(item)
                            self.backup_state.save_state()
                    return False
                
                if uploaded_id:
                    self.upload_stats['success'] += 1
                    
                    # LÆ°u log ngay
                    with self.log_lock:
                        self.backup_log['backed_up_files'][item_id] = {
                            'name': item_name,
                            'type': 'file',
                            'size': file_size,
                            'md5': original_md5,
                            'backup_id': uploaded_id,
                            'backup_time': datetime.now().isoformat()
                        }
                    
                    # Cleanup
                    try:
                        os.remove(local_path)
                        local_path = None
                    except:
                        pass
                    
                    # CHECKPOINT: LÆ°u cáº£ log vÃ  state sau má»—i file thÃ nh cÃ´ng
                    self.save_log()
                    with self.state_lock:
                        self.backup_state.state['total_files_processed'] += 1
                        self.backup_state.save_state()
                    
                    return True
                else:
                    self.upload_stats['failed'] += 1
                    with self.state_lock:
                        if item not in self.backup_state.state['failed_files']:
                            self.backup_state.state['failed_files'].append(item)
                            self.backup_state.save_state()
                    return False
            else:
                self.download_stats['failed'] += 1
                with self.state_lock:
                    if item not in self.backup_state.state['failed_files']:
                        self.backup_state.state['failed_files'].append(item)
                        self.backup_state.save_state()
                return False
        
        except Exception as e:
            print(f"âŒ Error: {e}")
            with self.state_lock:
                if item not in self.backup_state.state['failed_files']:
                    self.backup_state.state['failed_files'].append(item)
                    self.backup_state.save_state()
            return False
        
        finally:
            if local_path and os.path.exists(local_path):
                try:
                    os.remove(local_path)
                except:
                    pass
    
    def _process_files_batch(self, files, backup_folder_id):
        """Process batch"""
        if not files:
            return
        
        print(f"\nğŸš€ Äang xá»­ lÃ½ {len(files)} files...")
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            future_to_file = {
                executor.submit(self.process_single_file, file_item, backup_folder_id): file_item
                for file_item in files
            }
            
            completed = 0
            for future in concurrent.futures.as_completed(future_to_file, timeout=3600):
                if self.should_stop:
                    print("\nâ¸ï¸  Äang dá»«ng...")
                    executor.shutdown(wait=False, cancel_futures=True)
                    break
                
                completed += 1
                
                try:
                    future.result()
                except:
                    pass
                
                if completed % 20 == 0:
                    mem = psutil.virtual_memory().percent
                    if mem > 80:
                        gc.collect()
        
        if len(files) > 50:
            gc.collect()
    
    def _backup_folder_recursive(self, source_folder_id, backup_folder_id):
        """Backup Ä‘á»‡ quy"""
        if self.should_stop:
            return
        
        items = self.list_files_in_folder(source_folder_id)
        print(f"\nğŸ“Š TÃ¬m tháº¥y {len(items)} items")
        
        folders = [i for i in items if i['mimeType'] == 'application/vnd.google-apps.folder']
        files = [i for i in items if i['mimeType'] != 'application/vnd.google-apps.folder']
        
        # Folders
        for folder_item in folders:
            if self.should_stop:
                break
            
            item_id = folder_item['id']
            item_name = folder_item['name']
            
            if item_id in self.backup_log['backed_up_files']:
                continue
            
            print(f"\nğŸ“ Processing: {item_name}")
            new_folder_id = self.create_folder(item_name, backup_folder_id)
            
            if new_folder_id:
                self._backup_folder_recursive(item_id, new_folder_id)
                
                with self.log_lock:
                    self.backup_log['backed_up_files'][item_id] = {
                        'name': item_name,
                        'type': 'folder',
                        'backup_time': datetime.now().isoformat()
                    }
        
        # Files
        if files and not self.should_stop:
            self._process_files_batch(files, backup_folder_id)
    
    def smart_backup(self):
        """
        SMART BACKUP - Tá»± Ä‘á»™ng phÃ¡t hiá»‡n vÃ  resume
        KhÃ´ng cáº§n chá»n mode manual
        """
        
        # Kiá»ƒm tra cÃ³ state paused khÃ´ng
        if self.backup_state.state['status'] == 'paused':
            if not self.backup_state.can_resume():
                print("\nâ° ChÆ°a Ä‘á»§ 24h Ä‘á»ƒ resume")
                print("ğŸ’¡ HÃ£y quay láº¡i sau\n")
                return None
            
            # Auto resume
            print("\n" + "="*80)
            print("ğŸ”„ Tá»° Äá»˜NG RESUME - PhÃ¡t hiá»‡n backup Ä‘Ã£ bá»‹ dá»«ng")
            print("="*80)
            
            backup_folder_id = self.backup_state.state.get('backup_folder_id')
            
            if not backup_folder_id:
                print("âŒ KhÃ´ng tÃ¬m tháº¥y backup folder ID")
                return None
            
            print(f"ğŸ“ Backup folder: {backup_folder_id}")
            
            pending = self.backup_state.state.get('pending_files', [])
            failed = self.backup_state.state.get('failed_files', [])
            
            print(f"ğŸ“Š Pending: {len(pending)} | Failed: {len(failed)}")
            
            all_retry = pending + failed
            
            if all_retry:
                print(f"\nğŸ”„ Retry {len(all_retry)} files...")
                self._process_files_batch(all_retry, backup_folder_id)
                
                if not self.should_stop:
                    self.backup_state.update(
                        pending_files=[],
                        failed_files=[],
                        status='completed'
                    )
                    print("\nâœ… Resume hoÃ n táº¥t!")
            else:
                print("\nâœ… KhÃ´ng cÃ³ file cáº§n retry!")
                self.backup_state.update(status='completed')
            
            return backup_folder_id
        
        # Backup má»›i
        print("\n" + "="*80)
        print("ğŸ†• BACKUP Má»šI")
        print("="*80)
        
        source_info = self.get_file_info(SOURCE_FOLDER_ID)
        if not source_info:
            print("âŒ KhÃ´ng thá»ƒ láº¥y thÃ´ng tin source")
            return None
        
        backup_folder_name = source_info['name'] + FOLDER_SUFFIX
        backup_folder_id = self.create_folder(backup_folder_name, BACKUP_PARENT_ID)
        
        if not backup_folder_id:
            return None
        
        self.backup_state.update(
            status='in_progress',
            backup_folder_id=backup_folder_id,
            current_folder=SOURCE_FOLDER_ID
        )
        
        self.download_stats = {'success': 0, 'failed': 0, 'skipped': 0}
        self.upload_stats = {'success': 0, 'failed': 0}
        
        self._backup_folder_recursive(SOURCE_FOLDER_ID, backup_folder_id)
        
        self.save_log()
        
        if self.should_stop:
            print(f"\nâ¸ï¸  BACKUP Bá»Š Dá»ªNG")
        else:
            self.backup_state.update(status='completed')
            print(f"\nâœ… HOÃ€N Táº¤T!")
        
        print(f"\nğŸ“Š Download: âœ… {self.download_stats['success']} | "
              f"âŒ {self.download_stats['failed']} | â­ï¸ {self.download_stats['skipped']}")
        print(f"ğŸ“Š Upload: âœ… {self.upload_stats['success']} | âŒ {self.upload_stats['failed']}")
        
        return backup_folder_id
    
    def get_backup_stats(self):
        """Stats"""
        total = len(self.backup_log['backed_up_files'])
        files = sum(1 for i in self.backup_log['backed_up_files'].values() if i['type'] == 'file')
        folders = sum(1 for i in self.backup_log['backed_up_files'].values() if i['type'] == 'folder')
        
        print("\n" + "="*80)
        print("ğŸ“Š THá»NG KÃŠ")
        print("="*80)
        print(f"Tá»•ng: {total} | Files: {files} | Folders: {folders}")
        print(f"Láº§n cháº¡y cuá»‘i: {self.backup_log.get('last_run', 'ChÆ°a cÃ³')}")
        print(f"Tráº¡ng thÃ¡i: {self.backup_state.state['status']}")
        
        if self.backup_state.state.get('pending_files'):
            print(f"Pending: {len(self.backup_state.state['pending_files'])}")
        if self.backup_state.state.get('failed_files'):
            print(f"Failed: {len(self.backup_state.state['failed_files'])}")
        
        print("="*80 + "\n")


# ============================================================
# BÆ¯á»šC 6: KHá»I Táº O & CHáº Y
# ============================================================

print("ğŸ”§ Khá»Ÿi táº¡o Backup Manager...")
backup_manager = DriveBackupManager(
    drive_service,
    log_file=LOG_FILE,
    state_file=STATE_FILE,
    max_workers=MAX_WORKERS,
    manual_mode=MANUAL_RESUME_MODE
)

# Stats hiá»‡n táº¡i
backup_manager.get_backup_stats()

# ============================================================
# ğŸš€ CHáº Y BACKUP - Tá»° Äá»˜NG SMART
# ============================================================

print("\n" + "="*80)
print("ğŸ¯ WORKFLOW KHUYáº¾N NGHá»Š:")
print("="*80)
print("1. Cháº¡y backup bÃ¬nh thÆ°á»ng")
print("2. Náº¿u gáº·p rate limit â†’ Dá»ªNG RUNTIME")
print("3. Äá»£i 24h")
print("4. Khá»Ÿi Ä‘á»™ng láº¡i notebook â†’ Tá»° Äá»˜NG RESUME")
print("="*80 + "\n")

print("ğŸš€ Báº®T Äáº¦U BACKUP...")
start_time = time.time()

# SMART BACKUP - Tá»± Ä‘á»™ng phÃ¡t hiá»‡n resume hoáº·c backup má»›i
backup_folder_id = backup_manager.smart_backup()

end_time = time.time()

# ============================================================
# Káº¾T QUáº¢
# ============================================================

if backup_folder_id:
    duration = end_time - start_time
    print(f"\nâœ… THÃ€NH CÃ”NG!")
    print(f"â±ï¸  Thá»i gian: {duration:.2f}s ({duration/60:.2f} phÃºt)")
    print(f"ğŸ“ Backup Folder ID: {backup_folder_id}")
    print(f"ğŸ”— Link: https://drive.google.com/drive/folders/{backup_folder_id}")
    
    backup_manager.get_backup_stats()
elif backup_manager.should_stop:
    print(f"\nğŸ’¡ NEXT STEPS:")
    print("="*80)
    print("âœ… State Ä‘Ã£ Ä‘Æ°á»£c lÆ°u an toÃ n")
    print("âœ… Dá»ªNG RUNTIME NGAY (Runtime â†’ Disconnect)")
    print("âœ… Äá»£i 24h")
    print("âœ… Má»Ÿ láº¡i notebook â†’ Cháº¡y láº¡i â†’ Tá»± Ä‘á»™ng resume")
    print("="*80 + "\n")
else:
    print("\nâŒ BACKUP THáº¤T Báº I!")

# ============================================================
# TIá»†N ÃCH
# ============================================================

def view_state():
    """Xem state"""
    if os.path.exists(STATE_FILE):
        with open(STATE_FILE, 'r') as f:
            state = json.load(f)
            print("\nğŸ“Š STATE:")
            print(json.dumps(state, indent=2, ensure_ascii=False))

def view_log():
    """Xem log"""
    if os.path.exists(LOG_FILE):
        with open(LOG_FILE, 'r') as f:
            log = json.load(f)
            print(f"\nğŸ“Š LOG:")
            print(f"Total: {len(log['backed_up_files'])}")

def download_files():
    """Download files"""
    from google.colab import files
    for filename in [STATE_FILE, LOG_FILE]:
        if os.path.exists(filename):
            files.download(filename)
            print(f"âœ… Downloaded: {filename}")

print("""
================================================================================
                        TIá»†N ÃCH
================================================================================

view_state()      # Xem backup state
view_log()        # Xem backup log  
download_files()  # Download state + log vá» mÃ¡y

================================================================================
""")
