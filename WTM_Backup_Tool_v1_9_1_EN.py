# -*- coding: utf-8 -*-
"""
================================================================================
    GOOGLE DRIVE BACKUP TOOL v2.0 - ROBUST & ADVANCED
    Production-ready with proper error handling and memory management
================================================================================

VERSION: 2.0.0
DATE: February 04, 2026

KEY IMPROVEMENTS:
‚úÖ Proper rate limit detection across ALL operations
‚úÖ Circuit breaker pattern for rate limit handling
‚úÖ Memory leak prevention with proper cleanup
‚úÖ Thread-safe operations with context managers
‚úÖ Exponential backoff with jitter
‚úÖ Graceful shutdown handling
‚úÖ Comprehensive error recovery
‚úÖ Resource pooling for file handles
‚úÖ Atomic state updates

NON-BREAKING CHANGES:
- All existing config variables work as before
- State files are backward compatible
- API unchanged for user

MEMORY OPTIMIZATIONS:
- Proper file handle cleanup
- Bounded thread pool with resource limits
- Explicit garbage collection at checkpoints
- Stream processing for large files

================================================================================
"""

# ============================================================
# INSTALLATION
# ============================================================

print("üì¶ Installing dependencies...")
import subprocess
import sys

packages = [
    'google-auth',
    'google-auth-oauthlib',
    'google-auth-httplib2',
    'google-api-python-client',
    'tqdm',
    'requests',
    'psutil'
]

for package in packages:
    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', package])

print("‚úÖ Dependencies installed!\n")

# ============================================================
# IMPORTS
# ============================================================

import os
import json
import hashlib
import time
import random
from datetime import datetime, timedelta
from pathlib import Path
import io
import logging
import gc
import signal
import atexit
from threading import Lock, Event, RLock
from contextlib import contextmanager
import concurrent.futures
import multiprocessing
from collections import deque
from typing import Optional, Dict, List, Any, Tuple

# Google Drive API
from google.colab import auth
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload, MediaIoBaseDownload
from googleapiclient.errors import HttpError
from google.auth import default

# Progress bar
from tqdm.notebook import tqdm

# System monitoring
import psutil

# Suppress warnings
logging.getLogger('google_auth_httplib2').setLevel(logging.ERROR)

# ============================================================
# CONFIGURATION
# ============================================================

# üìÅ FOLDER IDs (REQUIRED)
SOURCE_FOLDER_ID = '1ZY4ab0XlPHa5asdsafghjFFFgeNx'  # ‚ö†Ô∏è CHANGE THIS
BACKUP_PARENT_ID = 'ABCDfghjFFFgeNx123124353xxa41'  # ‚ö†Ô∏è CHANGE THIS

# üè∑Ô∏è Settings
FOLDER_SUFFIX = '_BACKUP'
MAX_WORKERS = None  # Auto-detect

# üõ°Ô∏è Rate Limit Protection (Circuit Breaker Pattern)
RATE_LIMIT_THRESHOLD = 3          # Failures before circuit opens
RATE_LIMIT_COOLDOWN_HOURS = 24    # Cooldown period
RATE_LIMIT_WINDOW_SECONDS = 60    # Time window for counting errors

# üìù Files
LOG_FILE = 'backup_log.json'
STATE_FILE = 'backup_state.json'

# üéØ Mode
MANUAL_RESUME_MODE = True

# üîß Advanced Settings
CHUNK_SIZE = 10 * 1024 * 1024      # 10MB chunks
MAX_RETRIES = 3                     # Per operation retries
INITIAL_BACKOFF = 2                 # Initial backoff seconds
MAX_BACKOFF = 300                   # Max backoff seconds
MEMORY_CLEANUP_THRESHOLD = 80       # RAM % threshold for cleanup
MAX_FILE_HANDLES = 10               # Max concurrent file handles

print("="*80)
print("‚öôÔ∏è  CONFIGURATION:")
print("="*80)
print(f"üìÅ Source: {SOURCE_FOLDER_ID}")
print(f"üìÅ Backup Parent: {BACKUP_PARENT_ID}")
print(f"üéØ Mode: {'MANUAL RESUME' if MANUAL_RESUME_MODE else 'AUTO RESUME'}")
print(f"üõ°Ô∏è Rate Limit: {RATE_LIMIT_THRESHOLD} errors in {RATE_LIMIT_WINDOW_SECONDS}s")
print(f"üíæ Chunk Size: {CHUNK_SIZE / (1024*1024):.0f}MB")
print("="*80 + "\n")

# ============================================================
# AUTHENTICATION
# ============================================================

print("üîê Authenticating with Google Drive...")
auth.authenticate_user()
creds, _ = default()
drive_service = build('drive', 'v3', credentials=creds)
print("‚úÖ Authentication successful!\n")

# ============================================================
# UTILITY CLASSES
# ============================================================

class CircuitBreaker:
    """
    Circuit breaker pattern for rate limit protection.
    
    States:
    - CLOSED: Normal operation
    - OPEN: Too many failures, block all requests
    - HALF_OPEN: Testing if service recovered
    """
    
    def __init__(self, threshold: int, window_seconds: int, cooldown_hours: int):
        self.threshold = threshold
        self.window_seconds = window_seconds
        self.cooldown_seconds = cooldown_hours * 3600
        
        self.state = 'CLOSED'
        self.failures = deque()  # Timestamps of failures
        self.last_failure_time = None
        self.lock = RLock()
        
    def record_success(self):
        """Record successful operation"""
        with self.lock:
            if self.state == 'HALF_OPEN':
                self.state = 'CLOSED'
                self.failures.clear()
                
    def record_failure(self) -> bool:
        """
        Record failure and return True if circuit should open.
        
        Returns:
            bool: True if circuit breaker tripped
        """
        with self.lock:
            now = time.time()
            self.last_failure_time = now
            self.failures.append(now)
            
            # Remove old failures outside window
            cutoff = now - self.window_seconds
            while self.failures and self.failures[0] < cutoff:
                self.failures.popleft()
            
            # Check if threshold exceeded
            if len(self.failures) >= self.threshold:
                self.state = 'OPEN'
                return True
                
            return False
    
    def can_proceed(self) -> Tuple[bool, Optional[str]]:
        """
        Check if operation can proceed.
        
        Returns:
            Tuple[bool, Optional[str]]: (can_proceed, reason_if_blocked)
        """
        with self.lock:
            if self.state == 'CLOSED':
                return True, None
                
            if self.state == 'OPEN':
                if self.last_failure_time:
                    elapsed = time.time() - self.last_failure_time
                    
                    if elapsed >= self.cooldown_seconds:
                        self.state = 'HALF_OPEN'
                        return True, None
                    
                    remaining = self.cooldown_seconds - elapsed
                    next_time = datetime.fromtimestamp(
                        self.last_failure_time + self.cooldown_seconds
                    )
                    
                    return False, (
                        f"Circuit breaker OPEN. "
                        f"Wait {remaining/3600:.1f}h more. "
                        f"Resume after: {next_time.strftime('%Y-%m-%d %H:%M:%S')}"
                    )
                    
            if self.state == 'HALF_OPEN':
                return True, None
                
            return False, "Unknown circuit breaker state"
    
    def get_status(self) -> Dict[str, Any]:
        """Get current status"""
        with self.lock:
            return {
                'state': self.state,
                'failures_in_window': len(self.failures),
                'threshold': self.threshold,
                'last_failure': self.last_failure_time
            }


class ResourceManager:
    """
    Manage system resources to prevent memory leaks.
    """
    
    def __init__(self, max_file_handles: int):
        self.max_file_handles = max_file_handles
        self.active_handles = []
        self.lock = Lock()
        
    @contextmanager
    def get_file_handle(self, path: str, mode: str):
        """Context manager for file handles with automatic cleanup"""
        handle = None
        try:
            # Wait if too many handles open
            while len(self.active_handles) >= self.max_file_handles:
                time.sleep(0.1)
                self._cleanup_closed_handles()
            
            handle = open(path, mode)
            
            with self.lock:
                self.active_handles.append(handle)
            
            yield handle
            
        finally:
            if handle:
                try:
                    handle.close()
                except:
                    pass
                
                with self.lock:
                    if handle in self.active_handles:
                        self.active_handles.remove(handle)
    
    def _cleanup_closed_handles(self):
        """Remove closed handles from tracking"""
        with self.lock:
            self.active_handles = [h for h in self.active_handles if not h.closed]
    
    def cleanup_all(self):
        """Force cleanup all handles"""
        with self.lock:
            for handle in self.active_handles:
                try:
                    handle.close()
                except:
                    pass
            self.active_handles.clear()


class MemoryMonitor:
    """Monitor and manage memory usage"""
    
    def __init__(self, threshold_percent: int = 80):
        self.threshold = threshold_percent
        
    def check_and_cleanup(self) -> bool:
        """
        Check memory usage and cleanup if needed.
        
        Returns:
            bool: True if cleanup was performed
        """
        try:
            mem = psutil.virtual_memory()
            if mem.percent > self.threshold:
                gc.collect()
                return True
        except:
            pass
        return False
    
    def get_usage(self) -> Dict[str, Any]:
        """Get current memory usage"""
        try:
            mem = psutil.virtual_memory()
            return {
                'percent': mem.percent,
                'available_gb': mem.available / (1024**3),
                'total_gb': mem.total / (1024**3)
            }
        except:
            return {}


# ============================================================
# STATE MANAGEMENT
# ============================================================

class BackupState:
    """Thread-safe backup state management with atomic updates"""
    
    def __init__(self, state_file: str = 'backup_state.json'):
        self.state_file = state_file
        self.lock = RLock()
        self.state = self._load_state()
        
    def _load_state(self) -> Dict[str, Any]:
        """Load state from file"""
        if os.path.exists(self.state_file):
            try:
                with open(self.state_file, 'r', encoding='utf-8') as f:
                    state = json.load(f)
                    print(f"üìÇ Loaded state from {self.state_file}")
                    return state
            except Exception as e:
                print(f"‚ö†Ô∏è Failed to load state: {e}")
        
        return {
            'status': 'new',
            'version': '2.0',
            'backup_folder_id': None,
            'current_folder': None,
            'pending_files': [],
            'failed_files': [],
            'total_files_processed': 0,
            'circuit_breaker_state': 'CLOSED',
            'last_rate_limit_time': None,
            'created_at': datetime.now().isoformat(),
            'updated_at': datetime.now().isoformat()
        }
    
    def _save_state(self):
        """Save state to file (must be called within lock)"""
        try:
            self.state['updated_at'] = datetime.now().isoformat()
            
            # Atomic write using temp file
            temp_file = self.state_file + '.tmp'
            with open(temp_file, 'w', encoding='utf-8') as f:
                json.dump(self.state, f, indent=2, ensure_ascii=False)
            
            # Atomic rename
            os.replace(temp_file, self.state_file)
            
        except Exception as e:
            print(f"‚ö†Ô∏è Failed to save state: {e}")
    
    def update(self, **kwargs):
        """Thread-safe atomic update"""
        with self.lock:
            self.state.update(kwargs)
            self._save_state()
    
    def add_pending(self, file_item: Dict[str, Any]):
        """Add file to pending list"""
        with self.lock:
            if file_item not in self.state['pending_files']:
                self.state['pending_files'].append(file_item)
                self._save_state()
    
    def add_failed(self, file_item: Dict[str, Any]):
        """Add file to failed list"""
        with self.lock:
            if file_item not in self.state['failed_files']:
                self.state['failed_files'].append(file_item)
                self._save_state()
    
    def remove_from_pending(self, file_id: str):
        """Remove file from pending by ID"""
        with self.lock:
            self.state['pending_files'] = [
                f for f in self.state['pending_files'] 
                if f.get('id') != file_id
            ]
            self._save_state()
    
    def increment_processed(self):
        """Increment processed counter"""
        with self.lock:
            self.state['total_files_processed'] += 1
            self._save_state()
    
    def get_snapshot(self) -> Dict[str, Any]:
        """Get thread-safe snapshot of state"""
        with self.lock:
            return self.state.copy()


# ============================================================
# MAIN BACKUP MANAGER
# ============================================================

class DriveBackupManager:
    """
    Robust backup manager with proper error handling and resource management.
    """
    
    def __init__(
        self,
        service,
        log_file: str = 'backup_log.json',
        state_file: str = 'backup_state.json',
        max_workers: Optional[int] = None,
        manual_mode: bool = True
    ):
        self.service = service
        self.log_file = log_file
        self.manual_mode = manual_mode
        
        # State management
        self.backup_state = BackupState(state_file)
        self.backup_log = self._load_log()
        self.log_lock = RLock()
        
        # Circuit breaker for rate limiting
        self.circuit_breaker = CircuitBreaker(
            threshold=RATE_LIMIT_THRESHOLD,
            window_seconds=RATE_LIMIT_WINDOW_SECONDS,
            cooldown_hours=RATE_LIMIT_COOLDOWN_HOURS
        )
        
        # Resource management
        self.resource_manager = ResourceManager(MAX_FILE_HANDLES)
        self.memory_monitor = MemoryMonitor(MEMORY_CLEANUP_THRESHOLD)
        
        # Working directory
        self.local_temp_dir = '/content/temp_backup'
        os.makedirs(self.local_temp_dir, exist_ok=True)
        
        # Thread pool
        if max_workers is None:
            self.max_workers = self._auto_detect_workers()
        else:
            self.max_workers = max_workers
        
        # Shutdown handling
        self.shutdown_event = Event()
        self._setup_signal_handlers()
        
        # Stats
        self.stats = {
            'download': {'success': 0, 'failed': 0, 'skipped': 0},
            'upload': {'success': 0, 'failed': 0}
        }
        
        # Credentials for thread-local services
        self.creds, _ = default()
        
        print(f"üöÄ Workers: {self.max_workers}")
        print(f"üéØ Mode: {'MANUAL' if manual_mode else 'AUTO'}")
        print(f"üíæ Memory threshold: {MEMORY_CLEANUP_THRESHOLD}%")
        print()
    
    def __del__(self):
        """Cleanup on deletion"""
        self._cleanup()
    
    def _setup_signal_handlers(self):
        """Setup graceful shutdown handlers"""
        def shutdown_handler(signum, frame):
            print("\n‚ö†Ô∏è Shutdown signal received, cleaning up...")
            self.shutdown_event.set()
        
        try:
            signal.signal(signal.SIGINT, shutdown_handler)
            signal.signal(signal.SIGTERM, shutdown_handler)
        except:
            pass  # Signals might not work in Colab
        
        atexit.register(self._cleanup)
    
    def _cleanup(self):
        """Cleanup resources"""
        try:
            self.resource_manager.cleanup_all()
            
            if os.path.exists(self.local_temp_dir):
                for file in os.listdir(self.local_temp_dir):
                    try:
                        os.remove(os.path.join(self.local_temp_dir, file))
                    except:
                        pass
            
            gc.collect()
        except:
            pass
    
    def _auto_detect_workers(self) -> int:
        """Auto-detect optimal worker count"""
        try:
            mem_info = self.memory_monitor.get_usage()
            available_gb = mem_info.get('available_gb', 4)
            cpu_count = multiprocessing.cpu_count()
            
            workers_by_ram = max(1, int(available_gb / 0.3))
            workers_by_cpu = cpu_count
            optimal = max(3, min(workers_by_ram, workers_by_cpu, 8))
            
            print(f"üíæ RAM: {available_gb:.1f}GB | üñ•Ô∏è CPU: {cpu_count}")
            return optimal
        except:
            return 4
    
    def _load_log(self) -> Dict[str, Any]:
        """Load backup log"""
        if os.path.exists(self.log_file):
            try:
                with open(self.log_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except:
                pass
        
        return {
            'version': '2.0',
            'backed_up_files': {},
            'last_run': None
        }
    
    def _save_log(self):
        """Save backup log with atomic write"""
        with self.log_lock:
            try:
                self.backup_log['last_run'] = datetime.now().isoformat()
                
                temp_file = self.log_file + '.tmp'
                with open(temp_file, 'w', encoding='utf-8') as f:
                    json.dump(self.backup_log, f, indent=2, ensure_ascii=False)
                
                os.replace(temp_file, self.log_file)
            except Exception as e:
                print(f"‚ö†Ô∏è Failed to save log: {e}")
    
    def _get_thread_local_service(self):
        """Get thread-local Drive service"""
        return build('drive', 'v3', credentials=self.creds)
    
    def _is_rate_limit_error(self, error: Exception) -> bool:
        """Check if error is rate limit"""
        if isinstance(error, HttpError):
            return (
                error.resp.status == 403 and 
                'userRateLimitExceeded' in str(error)
            )
        return False
    
    def _exponential_backoff(self, attempt: int, jitter: bool = True) -> float:
        """Calculate backoff time with optional jitter"""
        backoff = min(INITIAL_BACKOFF * (2 ** attempt), MAX_BACKOFF)
        
        if jitter:
            backoff = backoff * (0.5 + random.random())
        
        return backoff
    
    def _handle_rate_limit(self) -> bool:
        """
        Handle rate limit error.
        
        Returns:
            bool: True if should stop execution
        """
        # Record failure in circuit breaker
        circuit_tripped = self.circuit_breaker.record_failure()
        
        if circuit_tripped:
            self.backup_state.update(
                status='paused',
                circuit_breaker_state='OPEN',
                last_rate_limit_time=datetime.now().isoformat()
            )
            
            print("\n" + "="*80)
            print("üö´ RATE LIMIT CIRCUIT BREAKER TRIPPED")
            print("="*80)
            print(f"‚ùå Detected {RATE_LIMIT_THRESHOLD} rate limit errors in {RATE_LIMIT_WINDOW_SECONDS}s")
            print(f"üíæ State saved to: {self.backup_state.state_file}")
            
            if self.manual_mode:
                self._print_manual_resume_instructions()
            else:
                print(f"\n‚è∞ Auto-resume after {RATE_LIMIT_COOLDOWN_HOURS}h")
            
            print("="*80 + "\n")
            
            self.shutdown_event.set()
            return True
        
        return False
    
    def _print_manual_resume_instructions(self):
        """Print instructions for manual resume"""
        next_run = datetime.now() + timedelta(hours=RATE_LIMIT_COOLDOWN_HOURS)
        
        print("\nüéØ MANUAL RESUME INSTRUCTIONS:")
        print("="*80)
        print("1Ô∏è‚É£ STOP RUNTIME NOW:")
        print("   ‚Üí Runtime ‚Üí Disconnect and delete runtime")
        print()
        print("2Ô∏è‚É£ WAIT 24 HOURS")
        print()
        print(f"3Ô∏è‚É£ RESUME AFTER: {next_run.strftime('%Y-%m-%d %H:%M:%S')}")
        print("   ‚Üí Reopen this notebook")
        print("   ‚Üí Run all cells ‚Üí Auto-resume")
        print()
        print("üìä PROGRESS SAVED:")
        
        snapshot = self.backup_state.get_snapshot()
        print(f"   ‚úÖ Completed: {len(self.backup_log['backed_up_files'])}")
        print(f"   ‚è≥ Pending: {len(snapshot['pending_files'])}")
        print(f"   ‚ùå Failed: {len(snapshot['failed_files'])}")
        print("="*80)
    
    def get_file_info(self, file_id: str) -> Optional[Dict[str, Any]]:
        """Get file metadata"""
        try:
            return self.service.files().get(
                fileId=file_id,
                fields='id, name, size, md5Checksum, mimeType'
            ).execute()
        except HttpError as e:
            print(f"‚ùå Error getting file info: {e}")
            return None
    
    def download_file(
        self,
        file_id: str,
        file_name: str,
        file_size: Optional[str] = None,
        service=None
    ) -> Optional[str]:
        """
        Download file with proper error handling and resource management.
        
        Returns:
            Optional[str]: Local path if successful, None otherwise
        """
        if self.shutdown_event.is_set():
            return None
        
        # Check circuit breaker
        can_proceed, reason = self.circuit_breaker.can_proceed()
        if not can_proceed:
            print(f"üö´ {reason}")
            return None
        
        if service is None:
            service = self.service
        
        local_path = os.path.join(self.local_temp_dir, file_name)
        
        for attempt in range(MAX_RETRIES):
            fh = None
            pbar = None
            
            try:
                request = service.files().get_media(fileId=file_id)
                
                with self.resource_manager.get_file_handle(local_path, 'wb') as fh:
                    downloader = MediaIoBaseDownload(
                        fh,
                        request,
                        chunksize=CHUNK_SIZE
                    )
                    
                    done = False
                    pbar = tqdm(
                        total=100,
                        desc=f"üì• {file_name[:30]}",
                        unit='%',
                        leave=False
                    )
                    
                    while not done and not self.shutdown_event.is_set():
                        status, done = downloader.next_chunk()
                        if status:
                            progress = int(status.progress() * 100)
                            pbar.update(progress - pbar.n)
                    
                    if pbar:
                        pbar.close()
                        pbar = None
                
                # Verify size if provided
                if file_size:
                    local_size = os.path.getsize(local_path)
                    if local_size != int(file_size):
                        raise Exception(
                            f"Size mismatch: expected {file_size}, got {local_size}"
                        )
                
                # Success - record in circuit breaker
                self.circuit_breaker.record_success()
                print(f"‚úÖ Downloaded: {file_name}")
                return local_path
                
            except Exception as e:
                # Handle rate limit
                if self._is_rate_limit_error(e):
                    print(f"üö´ Rate limit on download: {file_name}")
                    if self._handle_rate_limit():
                        return None
                
                print(f"‚ö†Ô∏è Download attempt {attempt + 1}/{MAX_RETRIES} failed: {e}")
                
                # Cleanup failed download
                if os.path.exists(local_path):
                    try:
                        os.remove(local_path)
                    except:
                        pass
                
                # Retry with backoff
                if attempt < MAX_RETRIES - 1:
                    backoff = self._exponential_backoff(attempt)
                    print(f"‚è≥ Retrying in {backoff:.1f}s...")
                    time.sleep(backoff)
                else:
                    print(f"‚ùå Download failed: {file_name}")
                    return None
            
            finally:
                if pbar:
                    try:
                        pbar.close()
                    except:
                        pass
        
        return None
    
    def upload_file(
        self,
        local_path: str,
        file_name: str,
        parent_folder_id: str,
        original_md5: Optional[str] = None,
        service=None
    ) -> Optional[str]:
        """
        Upload file with proper error handling.
        
        Returns:
            Optional[str]: Uploaded file ID if successful, None otherwise
        """
        if self.shutdown_event.is_set():
            return None
        
        # Check circuit breaker
        can_proceed, reason = self.circuit_breaker.can_proceed()
        if not can_proceed:
            print(f"üö´ {reason}")
            return None
        
        if service is None:
            service = self.service
        
        for attempt in range(MAX_RETRIES):
            uploaded_file_id = None
            
            try:
                file_metadata = {
                    'name': file_name,
                    'parents': [parent_folder_id]
                }
                
                media = MediaFileUpload(
                    local_path,
                    resumable=True,
                    chunksize=CHUNK_SIZE
                )
                
                file = service.files().create(
                    body=file_metadata,
                    media_body=media,
                    fields='id, name, size, md5Checksum'
                ).execute()
                
                uploaded_file_id = file['id']
                
                # Verify MD5 if provided
                if original_md5 and file.get('md5Checksum') != original_md5:
                    try:
                        service.files().delete(fileId=uploaded_file_id).execute()
                    except:
                        pass
                    raise Exception("MD5 checksum mismatch")
                
                # Success
                self.circuit_breaker.record_success()
                print(f"‚úÖ Uploaded: {file_name}")
                return uploaded_file_id
                
            except Exception as e:
                # Handle rate limit
                if self._is_rate_limit_error(e):
                    print(f"üö´ Rate limit on upload: {file_name}")
                    
                    # Cleanup uploaded file
                    if uploaded_file_id:
                        try:
                            service.files().delete(fileId=uploaded_file_id).execute()
                        except:
                            pass
                    
                    if self._handle_rate_limit():
                        return None
                
                print(f"‚ö†Ô∏è Upload attempt {attempt + 1}/{MAX_RETRIES} failed: {e}")
                
                # Cleanup failed upload
                if uploaded_file_id:
                    try:
                        service.files().delete(fileId=uploaded_file_id).execute()
                    except:
                        pass
                
                # Retry with backoff
                if attempt < MAX_RETRIES - 1:
                    backoff = self._exponential_backoff(attempt)
                    print(f"‚è≥ Retrying in {backoff:.1f}s...")
                    time.sleep(backoff)
                else:
                    print(f"‚ùå Upload failed: {file_name}")
                    return None
        
        return None
    
    def create_folder(
        self,
        folder_name: str,
        parent_id: Optional[str] = None
    ) -> Optional[str]:
        """Create folder"""
        try:
            file_metadata = {
                'name': folder_name,
                'mimeType': 'application/vnd.google-apps.folder'
            }
            
            if parent_id:
                file_metadata['parents'] = [parent_id]
            
            folder = self.service.files().create(
                body=file_metadata,
                fields='id, name'
            ).execute()
            
            print(f"üìÅ Created folder: {folder_name}")
            return folder['id']
            
        except HttpError as e:
            print(f"‚ùå Error creating folder: {e}")
            return None
    
    def list_files_in_folder(self, folder_id: str) -> List[Dict[str, Any]]:
        """List all files in folder"""
        items = []
        page_token = None
        
        try:
            while True:
                response = self.service.files().list(
                    q=f"'{folder_id}' in parents and trashed=false",
                    fields='nextPageToken, files(id, name, mimeType, size, md5Checksum)',
                    pageToken=page_token,
                    pageSize=100
                ).execute()
                
                items.extend(response.get('files', []))
                page_token = response.get('nextPageToken')
                
                if not page_token:
                    break
            
            return items
            
        except HttpError as e:
            print(f"‚ùå Error listing files: {e}")
            return []
    
    def process_single_file(
        self,
        item: Dict[str, Any],
        backup_folder_id: str
    ) -> bool:
        """
        Process single file with proper state management.
        
        Returns:
            bool: True if successful
        """
        if self.shutdown_event.is_set():
            self.backup_state.add_pending(item)
            return False
        
        item_id = item['id']
        item_name = item['name']
        file_size = item.get('size')
        original_md5 = item.get('md5Checksum')
        
        thread_service = None
        local_path = None
        
        try:
            # Get thread-local service
            thread_service = self._get_thread_local_service()
            
            # Check if already backed up
            with self.log_lock:
                if item_id in self.backup_log['backed_up_files']:
                    print(f"‚è≠Ô∏è Skipped (already backed up): {item_name}")
                    self.stats['download']['skipped'] += 1
                    return True
            
            # Download
            local_path = self.download_file(
                item_id,
                item_name,
                file_size,
                service=thread_service
            )
            
            if self.shutdown_event.is_set():
                self.backup_state.add_pending(item)
                return False
            
            if not local_path or not os.path.exists(local_path):
                self.stats['download']['failed'] += 1
                self.backup_state.add_failed(item)
                return False
            
            self.stats['download']['success'] += 1
            
            # Upload
            uploaded_id = self.upload_file(
                local_path,
                item_name,
                backup_folder_id,
                original_md5,
                service=thread_service
            )
            
            if self.shutdown_event.is_set():
                self.backup_state.add_pending(item)
                return False
            
            if not uploaded_id:
                self.stats['upload']['failed'] += 1
                self.backup_state.add_failed(item)
                return False
            
            self.stats['upload']['success'] += 1
            
            # Save to log (atomic operation)
            with self.log_lock:
                self.backup_log['backed_up_files'][item_id] = {
                    'name': item_name,
                    'type': 'file',
                    'size': file_size,
                    'md5': original_md5,
                    'backup_id': uploaded_id,
                    'backup_time': datetime.now().isoformat()
                }
            
            # Cleanup local file
            try:
                os.remove(local_path)
                local_path = None
            except:
                pass
            
            # Checkpoint: Save log and increment counter
            self._save_log()
            self.backup_state.increment_processed()
            self.backup_state.remove_from_pending(item_id)
            
            # Memory cleanup check
            self.memory_monitor.check_and_cleanup()
            
            return True
            
        except Exception as e:
            print(f"‚ùå Error processing {item_name}: {e}")
            self.backup_state.add_failed(item)
            return False
            
        finally:
            # Ensure local file cleanup
            if local_path and os.path.exists(local_path):
                try:
                    os.remove(local_path)
                except:
                    pass
    
    def process_files_batch(
        self,
        files: List[Dict[str, Any]],
        backup_folder_id: str
    ):
        """Process batch of files with thread pool"""
        if not files:
            return
        
        print(f"\nüöÄ Processing {len(files)} files...")
        
        with concurrent.futures.ThreadPoolExecutor(
            max_workers=self.max_workers
        ) as executor:
            futures = {
                executor.submit(
                    self.process_single_file,
                    file_item,
                    backup_folder_id
                ): file_item
                for file_item in files
            }
            
            completed = 0
            
            for future in concurrent.futures.as_completed(futures):
                if self.shutdown_event.is_set():
                    print("\n‚è∏Ô∏è Shutting down gracefully...")
                    executor.shutdown(wait=False, cancel_futures=True)
                    break
                
                completed += 1
                
                try:
                    future.result()
                except Exception as e:
                    print(f"‚ö†Ô∏è Future exception: {e}")
                
                # Periodic memory cleanup
                if completed % 20 == 0:
                    if self.memory_monitor.check_and_cleanup():
                        print(f"‚ôªÔ∏è Memory cleanup performed ({completed}/{len(files)})")
        
        # Final cleanup for large batches
        if len(files) > 50:
            gc.collect()
    
    def backup_folder_recursive(
        self,
        source_folder_id: str,
        backup_folder_id: str
    ):
        """Recursive backup with proper state management"""
        if self.shutdown_event.is_set():
            return
        
        # List items
        items = self.list_files_in_folder(source_folder_id)
        print(f"\nüìä Found {len(items)} items in folder")
        
        # Separate folders and files
        folders = [
            i for i in items
            if i['mimeType'] == 'application/vnd.google-apps.folder'
        ]
        files = [
            i for i in items
            if i['mimeType'] != 'application/vnd.google-apps.folder'
        ]
        
        # Process folders recursively
        for folder_item in folders:
            if self.shutdown_event.is_set():
                break
            
            item_id = folder_item['id']
            item_name = folder_item['name']
            
            # Skip if already backed up
            with self.log_lock:
                if item_id in self.backup_log['backed_up_files']:
                    print(f"‚è≠Ô∏è Skipped folder: {item_name}")
                    continue
            
            print(f"\nüìÅ Processing folder: {item_name}")
            
            # Create folder in backup
            new_folder_id = self.create_folder(item_name, backup_folder_id)
            
            if new_folder_id:
                # Recurse
                self.backup_folder_recursive(item_id, new_folder_id)
                
                # Mark folder as backed up
                with self.log_lock:
                    self.backup_log['backed_up_files'][item_id] = {
                        'name': item_name,
                        'type': 'folder',
                        'backup_id': new_folder_id,
                        'backup_time': datetime.now().isoformat()
                    }
                
                self._save_log()
        
        # Process files in batch
        if files and not self.shutdown_event.is_set():
            self.process_files_batch(files, backup_folder_id)
    
    def smart_backup(self) -> Optional[str]:
        """
        Smart backup with auto-resume detection.
        
        Returns:
            Optional[str]: Backup folder ID if successful
        """
        snapshot = self.backup_state.get_snapshot()
        
        # Check if resuming from paused state
        if snapshot['status'] == 'paused':
            # Check circuit breaker
            can_proceed, reason = self.circuit_breaker.can_proceed()
            if not can_proceed:
                print(f"\n‚è∞ {reason}")
                print("üí° Come back later to resume\n")
                return None
            
            # Resume
            print("\n" + "="*80)
            print("üîÑ AUTO-RESUME DETECTED")
            print("="*80)
            
            backup_folder_id = snapshot.get('backup_folder_id')
            if not backup_folder_id:
                print("‚ùå No backup folder ID found")
                return None
            
            print(f"üìÅ Backup folder: {backup_folder_id}")
            
            pending = snapshot.get('pending_files', [])
            failed = snapshot.get('failed_files', [])
            
            print(f"üìä Pending: {len(pending)} | Failed: {len(failed)}")
            
            # Retry all pending and failed files
            all_retry = pending + failed
            
            if all_retry:
                print(f"\nüîÑ Retrying {len(all_retry)} files...")
                self.process_files_batch(all_retry, backup_folder_id)
                
                if not self.shutdown_event.is_set():
                    self.backup_state.update(
                        pending_files=[],
                        failed_files=[],
                        status='completed',
                        circuit_breaker_state='CLOSED'
                    )
                    print("\n‚úÖ Resume completed!")
            else:
                print("\n‚úÖ No files to retry!")
                self.backup_state.update(status='completed')
            
            return backup_folder_id
        
        # New backup
        print("\n" + "="*80)
        print("üÜï STARTING NEW BACKUP")
        print("="*80)
        
        # Get source info
        source_info = self.get_file_info(SOURCE_FOLDER_ID)
        if not source_info:
            print("‚ùå Cannot get source folder info")
            return None
        
        # Create backup folder
        backup_folder_name = source_info['name'] + FOLDER_SUFFIX
        backup_folder_id = self.create_folder(backup_folder_name, BACKUP_PARENT_ID)
        
        if not backup_folder_id:
            return None
        
        # Update state
        self.backup_state.update(
            status='in_progress',
            backup_folder_id=backup_folder_id,
            current_folder=SOURCE_FOLDER_ID,
            circuit_breaker_state='CLOSED'
        )
        
        # Start recursive backup
        self.backup_folder_recursive(SOURCE_FOLDER_ID, backup_folder_id)
        
        # Save final log
        self._save_log()
        
        # Update final status
        if self.shutdown_event.is_set():
            print("\n‚è∏Ô∏è BACKUP PAUSED")
            self.backup_state.update(status='paused')
        else:
            print("\n‚úÖ BACKUP COMPLETED!")
            self.backup_state.update(status='completed')
        
        # Print stats
        self.print_stats()
        
        return backup_folder_id
    
    def print_stats(self):
        """Print comprehensive statistics"""
        print(f"\nüìä STATISTICS:")
        print("="*80)
        print(f"Download: ‚úÖ {self.stats['download']['success']} | "
              f"‚ùå {self.stats['download']['failed']} | "
              f"‚è≠Ô∏è {self.stats['download']['skipped']}")
        print(f"Upload:   ‚úÖ {self.stats['upload']['success']} | "
              f"‚ùå {self.stats['upload']['failed']}")
        
        total_backed_up = len(self.backup_log['backed_up_files'])
        files_count = sum(
            1 for item in self.backup_log['backed_up_files'].values()
            if item['type'] == 'file'
        )
        folders_count = sum(
            1 for item in self.backup_log['backed_up_files'].values()
            if item['type'] == 'folder'
        )
        
        print(f"\nTotal backed up: {total_backed_up}")
        print(f"  Files: {files_count}")
        print(f"  Folders: {folders_count}")
        
        # Circuit breaker status
        cb_status = self.circuit_breaker.get_status()
        print(f"\nCircuit Breaker: {cb_status['state']}")
        print(f"  Failures in window: {cb_status['failures_in_window']}/{cb_status['threshold']}")
        
        # Memory usage
        mem_usage = self.memory_monitor.get_usage()
        if mem_usage:
            print(f"\nMemory: {mem_usage['percent']:.1f}% used "
                  f"({mem_usage['available_gb']:.1f}GB available)")
        
        print("="*80 + "\n")
    
    def get_backup_summary(self):
        """Get backup summary"""
        snapshot = self.backup_state.get_snapshot()
        
        print("\n" + "="*80)
        print("üìä BACKUP SUMMARY")
        print("="*80)
        print(f"Status: {snapshot['status']}")
        print(f"Total processed: {snapshot['total_files_processed']}")
        print(f"Pending: {len(snapshot.get('pending_files', []))}")
        print(f"Failed: {len(snapshot.get('failed_files', []))}")
        print(f"Last run: {self.backup_log.get('last_run', 'Never')}")
        print("="*80 + "\n")


# ============================================================
# MAIN EXECUTION
# ============================================================

print("üîß Initializing Backup Manager...")
backup_manager = DriveBackupManager(
    drive_service,
    log_file=LOG_FILE,
    state_file=STATE_FILE,
    max_workers=MAX_WORKERS,
    manual_mode=MANUAL_RESUME_MODE
)

# Show current status
backup_manager.get_backup_summary()

# ============================================================
# RUN BACKUP
# ============================================================

print("\n" + "="*80)
print("üéØ RECOMMENDED WORKFLOW:")
print("="*80)
print("1. Run backup normally")
print("2. If rate limit occurs ‚Üí STOP RUNTIME")
print("3. Wait 24 hours")
print("4. Restart notebook ‚Üí Auto-resume")
print("="*80 + "\n")

print("üöÄ STARTING BACKUP...")
start_time = time.time()

# Run smart backup
backup_folder_id = backup_manager.smart_backup()

end_time = time.time()

# ============================================================
# RESULTS
# ============================================================

if backup_folder_id:
    duration = end_time - start_time
    print(f"\n‚úÖ SUCCESS!")
    print(f"‚è±Ô∏è Duration: {duration:.2f}s ({duration/60:.2f} minutes)")
    print(f"üìÅ Backup Folder ID: {backup_folder_id}")
    print(f"üîó Link: https://drive.google.com/drive/folders/{backup_folder_id}")
    
    backup_manager.get_backup_summary()
    
elif backup_manager.shutdown_event.is_set():
    print(f"\nüí° NEXT STEPS:")
    print("="*80)
    print("‚úÖ State saved safely")
    print("‚úÖ STOP RUNTIME NOW (Runtime ‚Üí Disconnect)")
    print("‚úÖ Wait 24 hours")
    print("‚úÖ Reopen notebook ‚Üí Run all ‚Üí Auto-resume")
    print("="*80 + "\n")
    
else:
    print("\n‚ùå BACKUP FAILED!")

# ============================================================
# UTILITIES
# ============================================================

def view_state():
    """View current state"""
    if os.path.exists(STATE_FILE):
        with open(STATE_FILE, 'r') as f:
            state = json.load(f)
            print("\nüìä CURRENT STATE:")
            print(json.dumps(state, indent=2, ensure_ascii=False))

def view_log():
    """View backup log"""
    if os.path.exists(LOG_FILE):
        with open(LOG_FILE, 'r') as f:
            log = json.load(f)
            print(f"\nüìä BACKUP LOG:")
            print(f"Total items: {len(log['backed_up_files'])}")
            print(f"Last run: {log.get('last_run', 'Never')}")

def download_files():
    """Download state and log files"""
    from google.colab import files
    for filename in [STATE_FILE, LOG_FILE]:
        if os.path.exists(filename):
            files.download(filename)
            print(f"‚úÖ Downloaded: {filename}")

def get_circuit_breaker_status():
    """Get circuit breaker status"""
    if 'backup_manager' in globals():
        status = backup_manager.circuit_breaker.get_status()
        print("\nüîå CIRCUIT BREAKER STATUS:")
        print(f"  State: {status['state']}")
        print(f"  Failures: {status['failures_in_window']}/{status['threshold']}")
        if status['last_failure']:
            last = datetime.fromtimestamp(status['last_failure'])
            print(f"  Last failure: {last.strftime('%Y-%m-%d %H:%M:%S')}")

def force_reset_circuit_breaker():
    """Force reset circuit breaker (use with caution)"""
    if 'backup_manager' in globals():
        backup_manager.circuit_breaker.state = 'CLOSED'
        backup_manager.circuit_breaker.failures.clear()
        backup_manager.backup_state.update(
            circuit_breaker_state='CLOSED',
            last_rate_limit_time=None
        )
        print("‚úÖ Circuit breaker reset!")

print("""
================================================================================
                        UTILITIES
================================================================================

view_state()                    # View current backup state
view_log()                      # View backup log
download_files()                # Download state + log files
get_circuit_breaker_status()    # Check circuit breaker
force_reset_circuit_breaker()   # Reset circuit breaker (caution!)

================================================================================
""")
